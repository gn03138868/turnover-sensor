# turnover_sensor_044.py
# è‡ªå‹•é¸æ“‡æœ€ä½³å°é½Šæ–¹æ³• / æœ€é©ãªæ•´åˆ—æ–¹æ³•ã®è‡ªå‹•é¸æŠ / Automatic best alignment method selection
# å€åŸŸé€£é€šåˆ†æ / é ˜åŸŸã®é€£çµæ€§åˆ†æ / Regional connectivity analysis
# ä¼°è¨ˆç”Ÿé•·èˆ‡åˆ†è§£é‡å¾Œç§»é™¤å™ªé» / ãƒã‚¤ã‚ºé™¤å»ã¯æˆé•·ã¨åˆ†è§£é‡ã®è¨ˆç®—å¾Œã«è¡Œã† / Noise filtering after growth/decomposition calculation
# å¹³ç§»+æ—‹è½¬+åˆ‡å˜+ç¼©æ”¾å°é½Š / å¹³è¡Œç§»å‹•+å›è»¢+ã›ã‚“æ–­+æ‹¡å¤§ç¸®å°ã§æ•´åˆ— / Alignment with translation+rotation+shear+scaling
# å¢åŠ OpticalFlow, Homography, å’ŒbUnwarpJéå‰›æ€§é…æº– / OpticalFlow, Homography,ã¨ bUnwarpJéå‰›æ€§ãƒ¬ã‚¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ / OpticalFlow, Homography, and bUnwarpJ non-rigid registration

import os
import cv2
import numpy as np
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import threading
import queue
import time
from skimage.morphology import remove_small_objects
import imagej
import tempfile
import tifffile
from scyjava import jimport

# å¼·åˆ¶ NumPy ä½¿ç”¨æ¨™æº– Python æ¨™é‡
np.set_printoptions(legacy='1.13')
pd._no_nep50_warning = True

# å®‰å…¨æ•´æ•¸è½‰æ›
def safe_int(value):
    """å®‰å…¨è½‰ç‚º int"""
    if hasattr(value, 'item'):
        return value.item()
    return int(value)

# å¼·åˆ¶ NumPy æ¨™ç¤ºè½‰æ›è¡Œç‚º
def convert_numpy_scalars(value):
    if isinstance(value, np.generic):
        return value.item()
    elif isinstance(value, list):
        return [convert_numpy_scalars(v) for v in value]
    elif isinstance(value, tuple):
        return tuple(convert_numpy_scalars(v) for v in value)
    elif isinstance(value, dict):
        return {k: convert_numpy_scalars(v) for k, v in value.items()}
    return value

# GPU æª¢æ¸¬
if cv2.cuda.getCudaEnabledDeviceCount() > 0:
    cv2.cuda.setDevice(0)
    USE_CUDA = True
else:
    USE_CUDA = False

FIJI_PATH = ""   # å…¨å±€ Fiji è·¯å¾‘
ij = None        # ImageJ å¯¦ä¾‹

def set_fiji_path():
    """è¨­ç½® Fiji è·¯å¾‘"""
    global FIJI_PATH
    path = filedialog.askdirectory(title="Select Fiji.app Directory")
    if path:
        FIJI_PATH = path
        messagebox.showinfo("Fiji Path Set", f"Fiji path set to: {FIJI_PATH}")

def initialize_imagej():
    """åˆå§‹åŒ– ImageJ/Fiji"""
    global ij
    if ij is not None:
        return ij
    if not FIJI_PATH:
        raise ValueError("Fiji path not set. Please set Fiji path first.")
    try:
        ij = imagej.init(FIJI_PATH, mode='interactive')
        print("ImageJ initialized successfully")
        return ij
    except Exception as e:
        raise RuntimeError(f"Failed to initialize ImageJ: {str(e)}")

def align_with_bunwarpj(reference_image, target_image, a4_width, a4_height):
    """ä½¿ç”¨ bUnwarpJ é€²è¡Œéå‰›æ€§é…æº–"""
    try:
        ij_instance = initialize_imagej()

        with tempfile.TemporaryDirectory() as temp_dir:
            ref_path = os.path.join(temp_dir, "reference.tif")
            target_path = os.path.join(temp_dir, "target.tif")

            # å…ˆä¿å­˜ç‚ºç°åº¦ tifï¼Œä¾› bUnwarpJ è¨ˆç®—è®Šå½¢å ´
            tifffile.imwrite(ref_path, cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY))
            tifffile.imwrite(target_path, cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY))

            IJ = jimport('ij.IJ')
            ImagePlus = jimport('ij.ImagePlus')
            bUnwarpJ = jimport('bunwarpj.bUnwarpJ_')

            ref_imp = IJ.openImage(ref_path)
            target_imp = IJ.openImage(target_path)
            if ref_imp is None or target_imp is None:
                raise RuntimeError("Failed to load images in ImageJ")

            # bUnwarpJ åƒæ•¸
            registration_mode = 0
            img_subsample_factor = 0
            min_scale_deformation = 0
            max_scale_deformation = 2
            divWeight = 0.1
            curlWeight = 0.1
            landmarkWeight = 0.0
            imageWeight = 1.0
            consistencyWeight = 10.0
            stopThreshold = 0.01

            transformation = bUnwarpJ.computeTransformationBatch(
                target_imp, ref_imp, None, None,
                registration_mode, img_subsample_factor,
                min_scale_deformation, max_scale_deformation,
                divWeight, curlWeight, landmarkWeight,
                imageWeight, consistencyWeight, stopThreshold
            )
            if transformation is None:
                raise RuntimeError("bUnwarpJ registration failed")

            transformed_imp = transformation.transform(target_imp)
            transformed_array = np.array(transformed_imp.getProcessor().getPixels(), dtype=np.uint8)
            h, w = target_image.shape[:2]
            transformed_array = transformed_array.reshape((h, w))
            aligned = cv2.cvtColor(transformed_array, cv2.COLOR_GRAY2BGR)

            # çµ±ä¸€ä½¿ç”¨ä¸­å¿ƒè£åˆ‡åˆ° A4 å°ºå¯¸
            return center_crop_to_a4(aligned, a4_width, a4_height)

    except Exception as e:
        print(f"bUnwarpJ alignment failed: {str(e)}")
        return center_crop_to_a4(target_image, a4_width, a4_height)


def write_uint8_png(src_tif, dst_png):
    """Read any bit-depth TIFF and write 8-bit PNG, preserving white points for masks"""
    arr = tifffile.imread(src_tif)
    if arr.dtype == np.uint8:
        cv2.imwrite(dst_png, arr)
        return
    if np.issubdtype(arr.dtype, np.floating) and float(arr.max()) <= 1.0:
        arr8 = (arr * 255).astype(np.uint8)
        cv2.imwrite(dst_png, arr8)
        return
    if np.issubdtype(arr.dtype, np.integer) and float(arr.max()) <= 255:
        arr8 = arr.astype(np.uint8)
        cv2.imwrite(dst_png, arr8)
        return
    arrf = arr.astype(np.float32)
    arr_min, arr_max = float(arrf.min()), float(arrf.max())
    if arr_max > arr_min:
        arr8 = ((arrf - arr_min) / (arr_max - arr_min) * 255).astype(np.uint8)
    else:
        arr8 = np.zeros_like(arrf, dtype=np.uint8)
    cv2.imwrite(dst_png, arr8)

def preprocess_first_image(image, target_w, target_h):
    """Crop or pad around image center to target size"""
    h, w = image.shape[:2]
    crop_w = min(w, target_w)
    crop_h = min(h, target_h)
    x1 = (w - crop_w) // 2
    y1 = (h - crop_h) // 2
    region = image[y1:y1+crop_h, x1:x1+crop_w]
    canvas = np.zeros((target_h, target_w, 3), dtype=np.uint8)
    x_offset = (target_w - crop_w) // 2
    y_offset = (target_h - crop_h) // 2
    canvas[y_offset:y_offset+crop_h, x_offset:x_offset+crop_w] = region
    return canvas


def center_crop_to_a4(image, a4_width, a4_height):
    """Center crop/pad image to exact A4 size with black padding"""
    h, w = image.shape[:2]
    
    # Create black canvas of A4 size
    canvas = np.zeros((a4_height, a4_width, 3), dtype=np.uint8)
    
    # Calculate crop dimensions (don't exceed A4 size)
    crop_h = min(h, a4_height)
    crop_w = min(w, a4_width)
    
    # Calculate crop start position (center of original image)
    start_y = (h - crop_h) // 2
    start_x = (w - crop_w) // 2
    
    # Crop from center of original image
    cropped = image[start_y:start_y + crop_h, start_x:start_x + crop_w]
    
    # Calculate placement position (center of canvas)
    canvas_y = (a4_height - crop_h) // 2
    canvas_x = (a4_width - crop_w) // 2
    
    # Place cropped image in center of canvas
    canvas[canvas_y:canvas_y + crop_h, canvas_x:canvas_x + crop_w] = cropped
    
    return canvas

def align_with_optical_flow(reference_image, target_image, a4_width, a4_height):
    """Non-rigid registration using dense optical flow (Farneback)"""
    ref_gray = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)
    tgt_gray = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY)
    flow = cv2.calcOpticalFlowFarneback(
        ref_gray, tgt_gray, None,
        pyr_scale=0.7, 
        levels=2, 
        winsize=21,
        iterations=5, 
        poly_n=7, 
        poly_sigma=1.5, 
        flags=0
    )
    h, w = target_image.shape[:2]
    y, x = np.mgrid[0:h, 0:w].astype(np.float32)
    map_x = x + flow[..., 0]
    map_y = y + flow[..., 1]
    aligned = cv2.remap(target_image, map_x, map_y, cv2.INTER_LINEAR)
    
    # çµ±ä¸€ä½¿ç”¨ä¸­å¿ƒè£åˆ‡åˆ° A4 å°ºå¯¸
    return center_crop_to_a4(aligned, a4_width, a4_height)

def align_with_homography(reference_image, target_image, a4_width, a4_height):
    """Perspective transformation using homography"""
    ref_gray = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)
    tgt_gray = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY)
    orb = cv2.ORB_create(nfeatures=1000)
    kp1, des1 = orb.detectAndCompute(ref_gray, None)
    kp2, des2 = orb.detectAndCompute(tgt_gray, None)
    if des1 is None or des2 is None or len(des1) < 4 or len(des2) < 4:
        return center_crop_to_a4(target_image, a4_width, a4_height)
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(des1, des2)
    matches = sorted(matches, key=lambda x: x.distance)
    if len(matches) < 4:
        return center_crop_to_a4(target_image, a4_width, a4_height)
    src_pts = np.float32([kp2[m.trainIdx].pt for m in matches[:50]]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp1[m.queryIdx].pt for m in matches[:50]]).reshape(-1, 1, 2)
    H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
    if H is None:
        return center_crop_to_a4(target_image, a4_width, a4_height)
    
    # å…ˆè®Šå½¢åˆ°åƒè€ƒåœ–åƒå°ºå¯¸ï¼Œå†çµ±ä¸€è£åˆ‡
    h_ref, w_ref = reference_image.shape[:2]
    aligned = cv2.warpPerspective(target_image, H, (w_ref, h_ref))
    return center_crop_to_a4(aligned, a4_width, a4_height)


def evaluate_alignment_quality(reference_image, aligned_image):
    """Evaluate alignment via SSIM + Normalized Cross Correlation"""
    ref_gray = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)
    aligned_gray = cv2.cvtColor(aligned_image, cv2.COLOR_BGR2GRAY)
    ref_f = ref_gray.astype(np.float32)
    aligned_f = aligned_gray.astype(np.float32)

    mu1 = cv2.GaussianBlur(ref_f, (11, 11), 1.5)
    mu2 = cv2.GaussianBlur(aligned_f, (11, 11), 1.5)
    mu1_sq = mu1 * mu1
    mu2_sq = mu2 * mu2
    mu1_mu2 = mu1 * mu2
    sigma1_sq = cv2.GaussianBlur(ref_f * ref_f, (11, 11), 1.5) - mu1_sq
    sigma2_sq = cv2.GaussianBlur(aligned_f * aligned_f, (11, 11), 1.5) - mu2_sq
    sigma12 = cv2.GaussianBlur(ref_f * aligned_f, (11, 11), 1.5) - mu1_mu2

    c1 = (0.01 * 255) ** 2
    c2 = (0.03 * 255) ** 2

    ssim_map = ((2 * mu1_mu2 + c1) * (2 * sigma12 + c2)) / ((mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2))
    ssim_score = np.mean(ssim_map)

    ref_norm = ref_f - np.mean(ref_f)
    aligned_norm = aligned_f - np.mean(aligned_f)
    ncc = np.sum(ref_norm * aligned_norm) / (np.sqrt(np.sum(ref_norm**2)) * np.sqrt(np.sum(aligned_norm**2)) + 1e-10)

    combined_score = 0.7 * ssim_score + 0.3 * ncc
    return combined_score, ssim_score, ncc

def try_all_alignment_methods(reference_image, target_image, a4_width, a4_height, progress_callback=None):
    """å˜—è©¦æ‰€æœ‰å°é½Šæ–¹æ³•ä¸¦é¸æ“‡æœ€ä½³çµæœ"""
    if USE_CUDA:
        gpu_ref = cv2.cuda_GpuMat()
        gpu_ref.upload(reference_image)
        gpu_tgt = cv2.cuda_GpuMat()
        gpu_tgt.upload(target_image)
        ref_gray = cv2.cuda.cvtColor(gpu_ref, cv2.COLOR_BGR2GRAY).download()
        tgt_gray = cv2.cuda.cvtColor(gpu_tgt, cv2.COLOR_BGR2GRAY).download()
    else:
        ref_gray = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)
        tgt_gray = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY)

    methods = ["Euclidean", "Affine", "OpticalFlow", "Homography"]
    if FIJI_PATH:
        methods.append("bUnwarpJ")

    results = []
    scores = []
    for method in methods:
        try:
            if progress_callback:
                progress_callback(0, f"Trying {method}...")
                
            if method == "Euclidean":
                warp_affine = np.eye(2, 3, dtype=np.float32)
                _, warp_matrix = cv2.findTransformECC(
                    ref_gray, tgt_gray,
                    warp_affine, cv2.MOTION_EUCLIDEAN,
                    (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-10), None, 5
                )
                h_ref, w_ref = reference_image.shape[:2]
                aligned = cv2.warpAffine(
                    target_image, warp_matrix,
                    (w_ref, h_ref),
                    flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP
                )
                aligned = center_crop_to_a4(aligned, a4_width, a4_height)
                
            elif method == "Affine":
                warp_affine = np.eye(2, 3, dtype=np.float32)
                _, warp_matrix = cv2.findTransformECC(
                    ref_gray, tgt_gray,
                    warp_affine, cv2.MOTION_AFFINE,
                    (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-10), None, 5
                )
                h_ref, w_ref = reference_image.shape[:2]
                aligned = cv2.warpAffine(
                    target_image, warp_matrix,
                    (w_ref, h_ref),
                    flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP
                )
                aligned = center_crop_to_a4(aligned, a4_width, a4_height)
                
            elif method == "OpticalFlow":
                aligned = align_with_optical_flow(reference_image, target_image, a4_width, a4_height)
            elif method == "Homography":
                aligned = align_with_homography(reference_image, target_image, a4_width, a4_height)
            elif method == "bUnwarpJ":
                aligned = align_with_bunwarpj(reference_image, target_image, a4_width, a4_height)
            else:
                continue

            score, ssim, ncc = evaluate_alignment_quality(reference_image, aligned)
            results.append((method, aligned, score, ssim, ncc))
            scores.append(score)
            if progress_callback:
                progress_callback(0, f"{method}: Score={score:.4f}")
        except Exception as e:
            print(f"{method} failed: {e}")
            if progress_callback:
                progress_callback(0, f"{method} failed: {str(e)[:50]}")
            continue

    if not results:
        return center_crop_to_a4(target_image, a4_width, a4_height), "None", 0.0, 0.0, 0.0

    best_idx = np.argmax(scores)
    best_method, best_aligned, best_score, best_ssim, best_ncc = results[best_idx]
    if progress_callback:
        progress_callback(0, f"Best: {best_method} (Score: {best_score:.4f})")
    return best_aligned, best_method, best_score, best_ssim, best_ncc
    

def align_single_method(reference_image, target_image, method, a4_width, a4_height):
    """ä½¿ç”¨æŒ‡å®šæ–¹æ³•é€²è¡Œå–®ä¸€å°é½Š"""
    if USE_CUDA:
        gpu_ref = cv2.cuda_GpuMat()
        gpu_ref.upload(reference_image)
        gpu_tgt = cv2.cuda_GpuMat()
        gpu_tgt.upload(target_image)
        ref_gray = cv2.cuda.cvtColor(gpu_ref, cv2.COLOR_BGR2GRAY).download()
        tgt_gray = cv2.cuda.cvtColor(gpu_tgt, cv2.COLOR_BGR2GRAY).download()
    else:
        ref_gray = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)
        tgt_gray = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY)

    try:
        if method == "Euclidean":
            warp_affine = np.eye(2, 3, dtype=np.float32)
            _, warp_matrix = cv2.findTransformECC(
                ref_gray, tgt_gray,
                warp_affine, cv2.MOTION_EUCLIDEAN,
                (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-10), None, 5
            )
            h_ref, w_ref = reference_image.shape[:2]
            aligned = cv2.warpAffine(
                target_image, warp_matrix,
                (w_ref, h_ref),
                flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP
            )
            return center_crop_to_a4(aligned, a4_width, a4_height)
            
        elif method == "Affine":
            warp_affine = np.eye(2, 3, dtype=np.float32)
            _, warp_matrix = cv2.findTransformECC(
                ref_gray, tgt_gray,
                warp_affine, cv2.MOTION_AFFINE,
                (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-10), None, 5
            )
            h_ref, w_ref = reference_image.shape[:2]
            aligned = cv2.warpAffine(
                target_image, warp_matrix,
                (w_ref, h_ref),
                flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP
            )
            return center_crop_to_a4(aligned, a4_width, a4_height)
            
        elif method == "OpticalFlow":
            return align_with_optical_flow(reference_image, target_image, a4_width, a4_height)
        elif method == "Homography":
            return align_with_homography(reference_image, target_image, a4_width, a4_height)
        elif method == "bUnwarpJ":
            return align_with_bunwarpj(reference_image, target_image, a4_width, a4_height)
        else:
            return center_crop_to_a4(target_image, a4_width, a4_height)

    except Exception as e:
        print(f"{method} alignment failed: {e}")
        return center_crop_to_a4(target_image, a4_width, a4_height)



def process_images_with_method(input_folder, output_folder, a4_width, a4_height, selected_method, progress_callback=None):
    """ä½¿ç”¨æŒ‡å®šæ–¹æ³•è™•ç†åœ–åƒ"""
    os.makedirs(output_folder, exist_ok=True)
    files = sorted([f for f in os.listdir(input_folder)
                    if f.lower().endswith(('.png','.jpg','.jpeg','.bmp'))])
    if not files:
        raise ValueError("No image files found in folder")

    results_log = []
    for i, fname in enumerate(files, start=1):
        img = cv2.imread(os.path.join(input_folder, fname))
        if img is None:
            continue

        # å°æ–¼ç¬¬ä¸€å¼µå°çš„åœ–ç‰‡é€²è¡Œç‰¹æ®Šè™•ç†
        if i == 1 and img.size < 100000:
            if progress_callback:
                progress_callback(0, f"æª¢æ¸¬åˆ°å°é«”ç©æª”æ¡ˆ: {fname}, æ‡‰ç”¨ç‰¹æ®Šè™•ç†")
            temp_img = img.copy()
            lab = cv2.cvtColor(temp_img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            lab = cv2.merge((l, a, b))
            temp_img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            temp_img = cv2.resize(temp_img, (a4_width, a4_height), interpolation=cv2.INTER_CUBIC)
            img = temp_img

        if progress_callback:
            progress_callback((i/len(files))*50, f"Processing {fname}")

        if i == 1:
            ref = preprocess_first_image(img, a4_width, a4_height)
            out = ref
            used_method = "Reference"
            score = ssim = ncc = 1.0
        else:
            resized = center_crop_to_a4(img, a4_width, a4_height)
            if selected_method == "Auto":
                out, used_method, score, ssim, ncc = try_all_alignment_methods(
                    ref, resized, a4_width, a4_height, progress_callback)
            else:
                out = align_single_method(ref, resized, selected_method, a4_width, a4_height)
                used_method = selected_method
                score, ssim, ncc = evaluate_alignment_quality(ref, out)

        output_filename = f"aligned_a4_{i:02d}.png"
        cv2.imwrite(os.path.join(output_folder, output_filename), out)

        results_log.append({
            'Image': fname,
            'Output': output_filename,
            'Selected_Method': selected_method,
            'Used_Method': used_method,
            'Combined_Score': score,
            'SSIM': ssim,
            'NCC': ncc
        })

        if progress_callback:
            progress_callback((i/len(files))*100,
                            f"Saved {output_filename} (Method: {used_method}, Score: {score:.4f})")

    results_df = pd.DataFrame(results_log)
    results_df.to_csv(os.path.join(output_folder, "alignment_results.csv"), index=False)
    return results_df

def process_ecc_fitting(input_folder, output_csv, output_visual_folder, a4_width, a4_height, progress_callback=None):
    """ECC æ“¬åˆè™•ç†èˆ‡åˆ†æ - ä¿®å¾©ç‰ˆæœ¬"""
    os.makedirs(output_visual_folder, exist_ok=True)
    
    # æª¢æŸ¥æ–‡ä»¶å¤¾æœ‰æ²’æœ‰åœ¨
    if not os.path.exists(input_folder):
        raise ValueError(f"Input folder does not exist: {input_folder}")
    
    files = sorted([f for f in os.listdir(input_folder) if f.lower().endswith(('.png','.jpg','.jpeg'))])
    
    # æª¢æŸ¥æœ‰æ²’æœ‰è¶³å¤ çš„åœ–ç‰‡é€²è¡Œå°æ¯”
    if len(files) < 2:
        raise ValueError(f"Need at least 2 images for ECC fitting. Found {len(files)} images in {input_folder}")
    
    results = []
    MIN_AREA = 500

    def calculate_area(binary_img):
        if binary_img is None or binary_img.size == 0:
            return 0
        return int(cv2.countNonZero(binary_img))

    for i in range(len(files)-1):
        try:
            if progress_callback:
                progress_callback(((i+1)/(len(files)-1))*100, f"Processing pair {i+1}/{len(files)-1}")
                
            p1 = os.path.join(input_folder, files[i])
            p2 = os.path.join(input_folder, files[i+1])
            
            # æ–‡ä»¶å­˜åœ¨æ€§æª¢æŸ¥
            if not os.path.exists(p1) or not os.path.exists(p2):
                print(f"File not found: {p1} or {p2}")
                continue
                
            img1 = cv2.imread(p1, cv2.IMREAD_GRAYSCALE)
            img2 = cv2.imread(p2, cv2.IMREAD_GRAYSCALE)
            
            if img1 is None or img2 is None:
                print(f"ç„¡æ³•è¼‰å…¥åœ–åƒ: {files[i]} æˆ– {files[i+1]}")
                continue

            # ç¢ºä¿åœ–ç‰‡å°ºå¯¸æ­£ç¢º
            if img1.shape != (a4_height, a4_width) or img2.shape != (a4_height, a4_width):
                img1 = cv2.resize(img1, (a4_width, a4_height), interpolation=cv2.INTER_LINEAR)
                img2 = cv2.resize(img2, (a4_width, a4_height), interpolation=cv2.INTER_LINEAR)

            # é©—è­‰A4å°ºå¯¸
            img1 = validate_a4_size(img1, a4_width, a4_height)
            img2 = validate_a4_size(img2, a4_width, a4_height)

            # äºŒæ¥µåŒ–
            _, b1 = cv2.threshold(img1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            _, b2 = cv2.threshold(img2, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

            # ECCé…å‡†
            warp = np.eye(2, 3, dtype=np.float32)
            try:
                criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 1000, 1e-6)
                _, warp = cv2.findTransformECC(
                    b1.astype(np.float32), b2.astype(np.float32), 
                    warp, cv2.MOTION_AFFINE, criteria, None, 3
                )
                b2a = cv2.warpAffine(b2, warp, (b1.shape[1], b1.shape[0]))
            except cv2.error as e:
                print(f"ECCå°é½Šå¤±æ•—æ–¼ {files[i]} -> {files[i+1]}: {str(e)}")
                b2a = b2.copy()

            # è¨ˆç®—é¢ç©
            a1 = calculate_area(b1)
            a2a = calculate_area(b2a)
            
            # ç¢ºä¿äºŒå€¼åœ–åƒæ ¼å¼æ­£ç¢º
            growth_area = cv2.bitwise_and(b2a, cv2.bitwise_not(b1))
            grow = calculate_area(growth_area)
            decomposition_area = cv2.bitwise_and(b1, cv2.bitwise_not(b2a))
            decomp = calculate_area(decomposition_area)

            # é€£é€šçµ„ä»¶éæ¿¾
            def filter_components(bin_img, min_area):
                if bin_img is None or bin_img.size == 0:
                    return np.zeros((a4_height, a4_width), dtype=np.uint8)
                    
                # ç¢ºä¿è¼¸å…¥æ˜¯uint8æ ¼å¼
                if bin_img.dtype != np.uint8:
                    bin_img = bin_img.astype(np.uint8)
                    
                num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(bin_img, connectivity=8)
                output = np.zeros_like(bin_img, dtype=np.uint8)
                
                for j in range(1, num_labels):
                    area = int(stats[j, cv2.CC_STAT_AREA])
                    if area < min_area:
                        continue
                    mask = np.where(labels == j, 255, 0).astype(np.uint8)
                    output = cv2.bitwise_or(output, mask)
                return output

            gbin = filter_components(growth_area, MIN_AREA)
            dbin = filter_components(decomposition_area, MIN_AREA)

            # å‰µå»ºè¦–è¦ºåŒ–åœ–åƒ
            vis = np.zeros((b1.shape[0], b1.shape[1], 3), dtype=np.uint8)
            vis[:, :, 1] = gbin  # ç¶ è‰²é€šé“ - ç”Ÿé•·
            vis[:, :, 2] = dbin  # ç´…è‰²é€šé“ - åˆ†è§£
            
            vis_filename = f"visual_{i+1:02d}.jpg"
            vis_path = os.path.join(output_visual_folder, vis_filename)
            cv2.imwrite(vis_path, vis)

            results.append({
                'Image1': files[i],
                'Image2': files[i+1],
                'Area1': safe_int(a1),
                'Area2_Aligned': safe_int(a2a),
                'Growth_Area': safe_int(grow),
                'Decomposition_Area': safe_int(decomp),
                'Growth_Filtered': safe_int(calculate_area(gbin)),
                'Decomp_Filtered': safe_int(calculate_area(dbin)),
                'Visual': vis_filename
            })

            if progress_callback:
                progress_callback(((i+1)/(len(files)-1))*100, f"Completed pair {i+1}/{len(files)-1}")
                
        except Exception as e:
            print(f"è™•ç†åœ–åƒå° {files[i]} å’Œ {files[i+1]} æ™‚å‡ºéŒ¯: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # å³ä½¿å‡ºéŒ¯ä¹Ÿè¦æ›´æ–°é€²åº¦ï¼Œé€™å°±æ˜¯äººç”Ÿ
            if progress_callback:
                progress_callback(((i+1)/(len(files)-1))*100, f"éŒ¯èª¤: {str(e)[:50]}")
            continue

    # æœ‰çµæœæ‰å­˜CSVï¼Œæ²’æœ‰çµæœï¼Œå°±çµ•å°ä¸æœƒå­˜
    if results:
        try:
            df = pd.DataFrame(results)
            df.to_csv(output_csv, index=False, encoding='utf-8-sig')
            print(f"ECC results saved to: {output_csv}")
            print(f"Processed {len(results)} image pairs successfully")
        except Exception as e:
            print(f"Error saving CSV: {e}")
            raise
    else:
        raise ValueError("æ²’æœ‰ç”¢ç”Ÿä»»ä½•çµæœï¼Œå¦‚åŒäººç”Ÿ - è«‹æª¢æŸ¥åœ–åƒæ ¼å¼å’Œå…§å®¹")

# é©—è­‰validate_a4_sizeå‡½æ•°ä¸­çš„å•é¡Œ
def validate_a4_size(image, expected_width, expected_height, tolerance=5):
    """é©—è­‰åœ–åƒæ˜¯å¦ç‚ºæ­£ç¢ºçš„ A4 å°ºå¯¸"""
    # ä¿®å¤8: å¤„ç†ç°åº¦å›¾åƒ
    if len(image.shape) == 2:  # ç°åº¦åœ–åƒ
        actual_height, actual_width = image.shape
    else:  # å½©è‰²åœ–åƒ
        actual_height, actual_width = image.shape[:2]
    
    width_diff = abs(actual_width - expected_width)
    height_diff = abs(actual_height - expected_height)
    
    if width_diff > tolerance or height_diff > tolerance:
        print(f"Warning: Image size mismatch - Expected: {expected_width}x{expected_height}, "
              f"Actual: {actual_width}x{actual_height}")
        
        # å¼·åˆ¶èª¿æ•´åˆ°æ­£ç¢ºå°ºå¯¸
        if actual_width != expected_width or actual_height != expected_height:
            resized = cv2.resize(image, (expected_width, expected_height), interpolation=cv2.INTER_LINEAR)
            print(f"Forced resize to A4 dimensions: {expected_width}x{expected_height}")
            return resized
    
    return image

def process_hsv_postprocessing(input_folder, progress_callback=None):
    """HSV å¾Œè™•ç†ç§»é™¤å°å™ªé»"""
    post_processed_images = os.path.join(input_folder, "post_processed")
    mask_folder = os.path.join(post_processed_images, 'masks')
    image_folder = os.path.join(post_processed_images, 'images')
    os.makedirs(mask_folder, exist_ok=True)
    os.makedirs(image_folder, exist_ok=True)

    lower_red1, upper_red1 = np.array([0, 100, 50]), np.array([10, 255, 255])
    lower_red2, upper_red2 = np.array([170, 100, 50]), np.array([180, 255, 255])
    lower_green, upper_green = np.array([35, 100, 50]), np.array([85, 255, 255])

    min_size = 1874
    files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', 'jpeg', '.png'))]
    total_files = len(files)
    if total_files == 0:
        raise ValueError("No image files found in the ECC visuals folder")

    for i, fn in enumerate(files):
        img_path = os.path.join(input_folder, fn)
        img = cv2.imread(img_path)
        if img is None:
            continue

        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        m1 = cv2.inRange(hsv, lower_red1, upper_red1)
        m2 = cv2.inRange(hsv, lower_red2, upper_red2)
        mask_red = cv2.bitwise_or(m1, m2)
        mask_green = cv2.inRange(hsv, lower_green, upper_green)

        red_large = remove_small_objects_opencv(mask_red, min_size)
        green_large = remove_small_objects_opencv(mask_green, min_size)

        red_small_mask = ((mask_red > 0) & ~(red_large > 0)).astype(np.uint8) * 255
        green_small_mask = ((mask_green > 0) & ~(green_large > 0)).astype(np.uint8) * 255

        mask_small = cv2.bitwise_or(red_small_mask, green_small_mask)
        kernel = np.ones((9, 9), np.uint8)
        mask_small_dil = cv2.dilate(mask_small, kernel, iterations=2)

        mask_save_path = os.path.join(mask_folder, fn.rsplit('.', 1)[0] + '_mask.png')
        cv2.imwrite(mask_save_path, mask_small_dil)

        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        inpainted = cv2.inpaint(img_rgb, mask_small_dil, inpaintRadius=15, flags=cv2.INPAINT_TELEA)
        out_bgr = cv2.cvtColor(inpainted, cv2.COLOR_RGB2BGR)
        out_path = os.path.join(image_folder, fn)
        cv2.imwrite(out_path, out_bgr)

        if progress_callback:
            progress_callback(((i + 1) / total_files) * 100)

def remove_small_objects_opencv(binary_image, min_size):
    """
    ä½¿ç”¨ç´” OpenCV ç§»é™¤å°é€£é€šçµ„ä»¶
    """
    if binary_image.dtype != np.uint8:
        binary_image = binary_image.astype(np.uint8)

    if binary_image.size == 0 or np.all(binary_image == 0):
        return np.zeros_like(binary_image)

    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(
        binary_image, connectivity=8
    )
    output = np.zeros_like(binary_image)

    for i in range(1, num_labels):
        area = int(stats[i, cv2.CC_STAT_AREA])
        if area < min_size:
            continue
        mask = np.where(labels == i, 255, 0).astype(np.uint8)
        output = cv2.bitwise_or(output, mask)

    return output

def process_images(input_folder, output_folder, a4_width, a4_height, progress_callback=None):
    """å˜—è©¦æ‰€æœ‰æ–¹æ³•æ‰¹é‡å°é½Šï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰"""
    os.makedirs(output_folder, exist_ok=True)
    files = sorted([f for f in os.listdir(input_folder)
                    if f.lower().endswith(('.png','.jpg','.jpeg','.bmp'))])
    if not files:
        raise ValueError("No image files found in folder")

    results_log = []
    for i, fname in enumerate(files, start=1):
        img = cv2.imread(os.path.join(input_folder, fname))
        if img is None:
            continue

        # ç¬¬ä¸€å¼µå¾ˆå°çš„åœ–ç‰‡åšç‰¹æ®Šè™•ç†
        if i == 1 and img.size < 100000:
            if progress_callback:
                progress_callback(0, f"æª¢æ¸¬åˆ°å°é›é›æ–‡ä»¶: {fname}, give it something special")
            temp_img = img.copy()
            lab = cv2.cvtColor(temp_img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            lab = cv2.merge((l, a, b))
            temp_img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            temp_img = cv2.resize(temp_img, (a4_width, a4_height), interpolation=cv2.INTER_CUBIC)
            img = temp_img

        if progress_callback:
            progress_callback((i/len(files))*50, f"Processing {fname}")

        if i == 1:
            ref = preprocess_first_image(img, a4_width, a4_height)
            out = ref
            best_method = "Reference"
            score = ssim = ncc = 1.0
        else:
            resized = center_crop_to_a4(img, a4_width, a4_height)
            out, best_method, score, ssim, ncc = try_all_alignment_methods(
                ref, resized, a4_width, a4_height, progress_callback)

        output_filename = f"aligned_a4_{i:02d}.png"
        cv2.imwrite(os.path.join(output_folder, output_filename), out)

        results_log.append({
            'Image': fname,
            'Output': output_filename,
            'Best_Method': best_method,
            'Combined_Score': score,
            'SSIM': ssim,
            'NCC': ncc
        })

        if progress_callback:
            progress_callback((i/len(files))*100,
                            f"Saved {output_filename} (Method: {best_method}, Score: {score:.4f})")

    results_df = pd.DataFrame(results_log)
    results_df.to_csv(os.path.join(output_folder, "alignment_results.csv"), index=False)
    return results_df

class Application(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("ğŸŒ³ Root Turnover Sensor æ ¹ç³»å›è»¢ã‚»ãƒ³ã‚µãƒ¼ ver. 0.44")
        self.geometry("800x800")
        self.configure(bg="#f7f7f7")
        self.folder_path = ""
        self.output_folder = ""
        self.progress_var = tk.DoubleVar()
        self.status_var = tk.StringVar(value="Status: Ready")
        self.elapsed_time_var = tk.StringVar(value="Elapsed Time: 0.00 s")
        self.queue = queue.Queue()
        self.create_widgets()
        self.after(100, self.process_queue)

    def start_fitting_thread(self):
        """Start ECC fitting thread from button"""
        if not self.folder_path:
            messagebox.showerror("Error", "Please select a folder.")
            return
        try:
            w = int(self.width_entry.get())
            h = int(self.height_entry.get())
        except ValueError:
            messagebox.showerror("Error", "Please enter valid width and height values.")
            return
        threading.Thread(target=self.start_fitting_process, args=(w, h), daemon=True).start()

    def start_fitting_process(self, a4_width, a4_height):
        """operate ECC fitting"""
        start_time = time.time()
        try:
            csv_path = os.path.join(self.folder_path, "ECC_results.csv")
            vis_folder = os.path.join(self.folder_path, "ECC_visuals")

            def progress_callback(progress, status=None):
                self.queue.put(("progress", progress))
                if status:
                    self.queue.put(("status", status))

            process_ecc_fitting(self.output_folder, csv_path, vis_folder, a4_width, a4_height, progress_callback)
            elapsed = time.time() - start_time
            self.queue.put(("done", elapsed))
        except Exception as e:
            self.queue.put(("error", str(e)))

    def start_hsv_thread(self):
        """Start HSV post-processing thread from button"""
        if not self.folder_path:
            messagebox.showerror("Error", "Please select a folder.")
            return
        ecc_visuals_folder = os.path.join(self.folder_path, "ECC_visuals")
        if not os.path.exists(ecc_visuals_folder):
            messagebox.showerror("Error", "ECC_visuals folder not found. Please run ECC Fitting first.")
            return
        threading.Thread(target=self.start_hsv_process, args=(ecc_visuals_folder,), daemon=True).start()

    def process_queue(self):
        """Process GUI update events from the queue"""
        try:
            while True:
                try:
                    evt = self.queue.get_nowait()
                    if evt[0] == "progress":
                        self.progress_var.set(evt[1])
                    elif evt[0] == "status":
                        self.status_var.set(evt[1])
                    elif evt[0] == "done":
                        self.elapsed_time_var.set(f"Elapsed Time: {evt[1]:.2f} s")
                        messagebox.showinfo("Success", "Processing complete! Check alignment_results.csv for statistics.")
                    elif evt[0] == "error":
                        error_msg = f"Error: {evt[1]}\n\nPlease check:\n1. All images same size\n"
                        error_msg += "2. Correct format (PNG, JPG)\n3. Sufficient features for alignment\n4. Correct A4 dimensions\n"
                        messagebox.showerror("Processing Error", error_msg)
                except queue.Empty:
                    break
        except Exception as e:
            messagebox.showerror("Queue Error", f"Error processing queue: {str(e)}")
        self.after(100, self.process_queue)

    def create_widgets(self):
        # æ¨™é¡Œ
        tk.Label(self, text="Turnover Sensor v0.43", font=("Helvetica",18,"bold"),
                 fg="#333", bg="#f7f7f7").pack(pady=10)

        # æ–°åŠŸèƒ½èªªæ˜
        info_frame = tk.LabelFrame(self, text="ğŸ†• New Feature æ–°æ©Ÿèƒ½",
                                  bg="#f7f7f7", fg="#0066cc", padx=10, pady=5)
        info_frame.pack(pady=5, fill="x", padx=20)
        tk.Label(info_frame,
                text="Select alignment method or use Auto mode for best results\næ•´åˆ—æ–¹æ³•ã‚’é¸æŠã™ã‚‹ã‹ã€è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ã§æœ€è‰¯ã®çµæœã‚’å¾—ã‚‹",
                bg="#f7f7f7", fg="#0066cc", font=("Arial", 9)).pack()

        # Fiji è·¯å¾‘è¨­ç½®
        fiji_frame = tk.Frame(self, bg="#f7f7f7")
        fiji_frame.pack(pady=5)
        ttk.Button(fiji_frame, text="ğŸ”§ Set Fiji Path", command=set_fiji_path).pack(side=tk.LEFT, padx=5)
        tk.Label(fiji_frame, text="Optional: For advanced non-rigid registration",
                 bg="#f7f7f7", fg="#666").pack(side=tk.LEFT)

        # å°ºå¯¸è¨­ç½®
        size_frame = tk.Frame(self, bg="#f7f7f7")
        size_frame.pack(pady=10)
        tk.Label(size_frame, text="Width å¹… (px):", bg="#f7f7f7").grid(row=0, column=0, padx=5)
        self.width_entry = tk.Entry(size_frame, width=10)
        self.width_entry.grid(row=0, column=1, padx=5)
        self.width_entry.insert(0, "4961")
        tk.Label(size_frame, text="Height é«˜ã• (px):", bg="#f7f7f7").grid(row=0, column=2, padx=5)
        self.height_entry = tk.Entry(size_frame, width=10)
        self.height_entry.grid(row=0, column=3, padx=5)
        self.height_entry.insert(0, "7016")

        # æ–¹æ³•é¸æ“‡
        method_frame = tk.LabelFrame(self, text="ğŸ¯ Alignment Method Selection æ•´åˆ—æ–¹æ³•é¸æŠ",
                                   bg="#f7f7f7", fg="#0066cc", padx=10, pady=10)
        method_frame.pack(pady=10, fill="x", padx=20)
        self.method_var = tk.StringVar(value="Auto")
        methods = [
            ("Auto (Battle Royale ãƒãƒˆãƒ«ãƒ»ãƒ­ãƒ¯ã‚¤ã‚¢ãƒ«)", "Auto"),
            ("Euclidean (å¹³ç§»+å›è»¢)", "Euclidean"),
            ("Affine (å¹³ç§»+å›è»¢+æ‹¡ç¸®+ã›ã‚“æ–­)", "Affine"),
            ("OpticalFlow (å¯†ãªéå‰›æ€§å¤‰å½¢)", "OpticalFlow"),
            ("Homography (é€è¦–å¤‰æ›)", "Homography"),
            ("bUnwarpJ (éå‰›æ€§å¤‰å½¢)", "bUnwarpJ")
        ]
        for i, (text, value) in enumerate(methods):
            ttk.Radiobutton(method_frame, text=text, variable=self.method_var,
                           value=value).grid(row=i//2, column=i%2, sticky="w", padx=10, pady=2)

        # æ–¹æ³•èªªæ˜
        method_info_frame = tk.LabelFrame(self, text="Method Details æ–¹æ³•è©³ç´°",
                                         bg="#f7f7f7", padx=10, pady=10)
        method_info_frame.pack(pady=10, fill="x", padx=20)
        methods_text = (
            "â€¢ Auto: Automatically selects best method based on quality scores\n"
            "â€¢ Euclidean: Translation + Rotation å¹³ç§»+å›è»¢\n"
            "â€¢ Affine: Translation + Rotation + Scale + Shear å¹³ç§»+å›è»¢+æ‹¡ç¸®+ã›ã‚“æ–­\n"
            "â€¢ OpticalFlow: Dense non-rigid deformation å¯†ãªéå‰›æ€§å¤‰å½¢\n"
            "â€¢ Homography: Perspective transformation é€è¦–å¤‰æ›\n"
            "â€¢ bUnwarpJ: Advanced non-rigid registration using Fiji"
        )
        tk.Label(method_info_frame, text=methods_text, bg="#f7f7f7",
                justify=tk.LEFT, font=("Arial", 9)).pack(anchor="w")

        # æ“ä½œæŒ‰é’®
        btn_frame = tk.Frame(self, bg="#f7f7f7")
        btn_frame.pack(pady=15)
        ttk.Button(btn_frame, text="ğŸ“ Select Folder ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ",
                  command=self.select_folder).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="ğŸ¯ Align Images æ•´åˆ—",
                  command=self.start_align_thread).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="ğŸ“Š ECC Fitting æ“¬åˆåˆ†æ",
                  command=self.start_fitting_thread).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="ğŸ¨ HSV Post-processing HSVå¾Œå‡¦ç†",
                  command=self.start_hsv_thread).pack(side=tk.LEFT, padx=5)

        # çŠ¶æ€æ˜¾ç¤º
        tk.Label(self, textvariable=self.status_var, font=("Arial",10),
                fg="#444", bg="#f7f7f7").pack(pady=5)
        ttk.Progressbar(self, variable=self.progress_var, maximum=100).pack(
            pady=15, fill="x", padx=20)
        tk.Label(self, textvariable=self.elapsed_time_var, font=("Arial",12),
                fg="#555", bg="#f7f7f7").pack(pady=10)

        # ç‰ˆæƒä¿¡æ¯
        tk.Label(self,
                text="Developed by the Forest Utilisation Lab in collaboration with ARATA meeting members. Copyright Â© 2025.",
                bd=1, relief=tk.SUNKEN, anchor=tk.W).pack(side=tk.BOTTOM, fill=tk.X)

    def select_folder(self):
        """select folder"""
        self.folder_path = filedialog.askdirectory(title="Select Folder")
        if self.folder_path:
            self.output_folder = os.path.join(self.folder_path, "aligned_images")
            os.makedirs(self.output_folder, exist_ok=True)
            self.status_var.set(f"Selected folder: {os.path.basename(self.folder_path)}")

    def start_align_thread(self):
        """start to align"""
        if not self.folder_path:
            messagebox.showerror("Error", "Please select a folder.")
            return
        try:
            w = int(self.width_entry.get())
            h = int(self.height_entry.get())
        except ValueError:
            messagebox.showerror("Error", "Please enter valid width and height values.")
            return
        threading.Thread(target=self.start_align_process, args=(w, h), daemon=True).start()

    def start_align_process(self, a4_width, a4_height):
        """to operate alignment"""
        start_time = time.time()
        try:
            def progress_callback(progress, status=None):
                # This callback will safely forward progress and status to the GUI
                self.queue.put(("progress", progress))
                if status:
                    self.queue.put(("status", status))

            selected_method = self.method_var.get()
            results_df = process_images_with_method(
                self.folder_path,
                self.output_folder,
                a4_width,
                a4_height,
                selected_method,
                progress_callback  # Passed into alignment logic
            )
    
            elapsed = time.time() - start_time
            if selected_method == "Auto":
                method_counts = results_df['Used_Method'].value_counts()
                stats_msg = "Auto mode - Methods used: " + \
                            ", ".join([f"{k}:{v}" for k, v in method_counts.items()])
            else:
                avg_score = results_df['Combined_Score'].mean()
                stats_msg = f"Fixed method: {selected_method}, Avg Score: {avg_score:.4f}"

            self.queue.put(("done", elapsed))
            self.queue.put(("status", f"Complete! {stats_msg}"))

        except Exception as e:
            self.queue.put(("error", str(e)))

    def start_hsv_process(self, ecc_visuals_folder):
        """operate HSV post-processing"""
        start_time = time.time()
        try:
            def progress_callback(progress, status=None):
                self.queue.put(("progress", progress))
                if status:
                    self.queue.put(("status", status))

            process_hsv_postprocessing(ecc_visuals_folder, progress_callback)
            elapsed = time.time() - start_time
            self.queue.put(("done", elapsed))
            self.queue.put(("status", "HSV post-processing completed! Check post_processed folder."))
        except Exception as e:
            self.queue.put(("error", str(e)))


if __name__ == "__main__":
    app = Application()
    app.mainloop()